{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e980951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://github.com/orgs/google/repositories/orgs/google/repositories\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://github.com/orgs/google/repositories/orgs/google/repositories",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 151\u001b[39m\n\u001b[32m    148\u001b[39m     con.close()\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle_repos.db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(max_pages, db_path)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m page_url \u001b[38;5;129;01mand\u001b[39;00m pages_fetched < max_pages:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     html = \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     repos = extract_repos_from_list_page(html)\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m - Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(repos)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m repos on this page\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mfetch\u001b[39m\u001b[34m(url, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, timeout=(\u001b[32m10\u001b[39m, \u001b[32m60\u001b[39m)) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     34\u001b[39m     resp = requests.get(url, headers=HEADERS, timeout=timeout)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dsprog2_2025_2/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://github.com/orgs/google/repositories/orgs/google/repositories"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import sqlite3\n",
    "from typing import List, Dict, Optional\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "BASE_URL = \"https://github.com/orgs/google/repositories?type=all\"\n",
    "ORG = \"google\"\n",
    "LIST_URL = f\"{BASE_URL}/orgs/{ORG}/repositories\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"google-repos-scraper/1.0 (+contact@example.com)\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Connection\": \"close\",\n",
    "}\n",
    "\n",
    "def parse_star_count(text: str) -> int:\n",
    "    # 例: \"1.2k\", \"3,456\", \"987\", \"2.1M\"\n",
    "    t = text.strip().lower().replace(\",\", \"\")\n",
    "    m = re.match(r\"^([0-9]+(?:\\.[0-9]+)?)([km]?)$\", t)\n",
    "    if not m:\n",
    "        return 0\n",
    "    num = float(m.group(1))\n",
    "    suffix = m.group(2)\n",
    "    if suffix == \"k\":\n",
    "        num *= 1_000\n",
    "    elif suffix == \"m\":\n",
    "        num *= 1_000_000\n",
    "    return int(num)\n",
    "\n",
    "def fetch(url: str, timeout=(10, 60)) -> str:\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "\n",
    "def extract_repos_from_list_page(html: str) -> List[Dict[str, Optional[str]]]:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    results = []\n",
    "    # 各リポジトリカードを探す\n",
    "    # GitHubはマークアップが変わる可能性があるため、複数候補セレクタを試す\n",
    "    repo_cards = soup.select(\"li[data-test-selector='repo-list-item']\") or \\\n",
    "                 soup.select(\"div.org-repos li\") or \\\n",
    "                 soup.select(\"div[data-test-selector='org-repositories'] li\")\n",
    "    for card in repo_cards:\n",
    "        # リポジトリ名リンク（例: <a data-testid=\"repo-name-link\" href=\"/google/guava\">guava</a>）\n",
    "        name = None\n",
    "        link = card.select_one(\"a[href*='/{}/']\".format(ORG)) or \\\n",
    "               card.select_one(\"a[data-testid='repo-name-link']\") or \\\n",
    "               card.select_one(\"a[href^='/{}/']\".format(ORG))\n",
    "        if link:\n",
    "            name = link.get_text(strip=True)\n",
    "            # たまに \"google / repo\" のように含む場合は末尾を採用\n",
    "            if \"/\" in name:\n",
    "                name = name.split(\"/\")[-1].strip()\n",
    "\n",
    "        # 言語（例: <span itemprop=\"programmingLanguage\">Java</span>）\n",
    "        lang = None\n",
    "        lang_el = card.select_one(\"[itemprop='programmingLanguage']\") or \\\n",
    "                  card.select_one(\"span:has(svg[aria-label='Programming language'])\") or \\\n",
    "                  card.find(\"span\", string=True)\n",
    "        if lang_el and getattr(lang_el, \"get_text\", None):\n",
    "            cand = lang_el.get_text(strip=True)\n",
    "            # 明らかに不適切な文言を除外\n",
    "            if cand and len(cand) <= 30 and \"Updated\" not in cand and \"Star\" not in cand:\n",
    "                lang = cand\n",
    "\n",
    "        # スター（例: <a href=\"/google/guava/stargazers\">1.2k</a>）\n",
    "        stars = 0\n",
    "        star_el = None\n",
    "        for sel in [\n",
    "            \"a[href$='/stargazers']\",\n",
    "            \"a.Link--muted[href$='/stargazers']\",\n",
    "            \"a[aria-label*='star'][href$='/stargazers']\",\n",
    "        ]:\n",
    "            star_el = card.select_one(sel)\n",
    "            if star_el:\n",
    "                break\n",
    "        if star_el:\n",
    "            stars = parse_star_count(star_el.get_text(strip=True))\n",
    "\n",
    "        if name:\n",
    "            results.append({\"name\": name, \"language\": lang, \"stars\": stars})\n",
    "    return results\n",
    "\n",
    "def find_next_page_url(html: str, current_url: str) -> Optional[str]:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # ページネーションのNextリンク\n",
    "    next_link = soup.select_one(\"a.next_page\") or soup.select_one(\"a[rel='next']\")\n",
    "    if next_link and next_link.get(\"href\"):\n",
    "        return urljoin(current_url, next_link[\"href\"])\n",
    "    return None\n",
    "\n",
    "# DB関連\n",
    "def init_db(db_path: str = \"repos.db\"):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS repos (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            name TEXT UNIQUE,\n",
    "            language TEXT,\n",
    "            stars INTEGER\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.commit()\n",
    "    return con\n",
    "\n",
    "def upsert_repos(con, repos: List[Dict[str, Optional[str]]]):\n",
    "    cur = con.cursor()\n",
    "    for r in repos:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO repos (name, language, stars)\n",
    "            VALUES (?, ?, ?)\n",
    "            ON CONFLICT(name) DO UPDATE SET\n",
    "                language=excluded.language,\n",
    "                stars=excluded.stars\n",
    "        \"\"\", (r[\"name\"], r.get(\"language\"), r.get(\"stars\", 0)))\n",
    "    con.commit()\n",
    "\n",
    "def main(max_pages: int = 5, db_path: str = \"repos.db\"):\n",
    "    con = init_db(db_path)\n",
    "\n",
    "    page_url = LIST_URL\n",
    "    pages_fetched = 0\n",
    "\n",
    "    while page_url and pages_fetched < max_pages:\n",
    "        print(f\"Fetching: {page_url}\")\n",
    "        html = fetch(page_url)\n",
    "        repos = extract_repos_from_list_page(html)\n",
    "        print(f\" - Found {len(repos)} repos on this page\")\n",
    "        upsert_repos(con, repos)\n",
    "        pages_fetched += 1\n",
    "\n",
    "        # 連続アクセス抑制\n",
    "        time.sleep(1)\n",
    "\n",
    "        next_url = find_next_page_url(html, page_url)\n",
    "        page_url = next_url\n",
    "\n",
    "    # 保存内容の確認表示\n",
    "    cur = con.cursor()\n",
    "    for row in cur.execute(\"SELECT name, language, stars FROM repos ORDER BY stars DESC, name ASC\"):\n",
    "        name, lang, stars = row\n",
    "        print(f\"{name}\\t{lang or ''}\\t{stars}\")\n",
    "\n",
    "    con.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(max_pages=1000, db_path=\"google_repos.db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
